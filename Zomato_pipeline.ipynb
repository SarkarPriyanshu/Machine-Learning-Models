{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXzKNI0Ulq+rXDR2fCUcCI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarkarPriyanshu/Machine-Learning-Models/blob/main/Zomato_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install feature_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VY_lBjJjWyH",
        "outputId": "05828502-f284-4122-a63e-043129129e23"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "56-lh5eoY19C"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        " \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer,AddMissingIndicator,CategoricalImputer\n",
        "from feature_engine.transformation import LogTransformer\n",
        "from feature_engine.encoding import OrdinalEncoder,OneHotEncoder\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# to build the models\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Vp-ef-Y8fM",
        "outputId": "e302525d-4658-4f1a-d311-be77d3137254"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class handleMixLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables:str=None,target:str=None,tol:int=10):\n",
        "    self.variables = variables\n",
        "    self.__keys = list()\n",
        "    self.__values = list()\n",
        "    self.tol = tol\n",
        "    self.target = target\n",
        "    self.all_unique_feature_type = list()\n",
        "    self.top_unique_feature_type_ = list()\n",
        "    self.unique_rare_feature_type_ = list()\n",
        "  \n",
        "  # we check the top 10 cardinal value which have monotonic relation with target column store that in keys\n",
        "  # go through the column if it have mixed or comma seperated values the carefully store all unique cardinal values store in all_unique_feature_type\n",
        "  # based on tolerance it take top cardinal values default value is 10 and store those top values in top_unique_feature_type_\n",
        "  def fit(self, X: pd.DataFrame,y:pd.Series):\n",
        "        X = X.dropna().copy()\n",
        "        X[self.target] = y\n",
        "        X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "       \n",
        "        if X[self.target].dtypes != float:\n",
        "          X[self.target] = X[self.target].str.replace(',','').astype(float)\n",
        "        \n",
        "        for key,value in X.groupby(self.variables)[self.target].mean().sort_values(ascending=False).items():\n",
        "                  self.__keys.append(key)\n",
        "                  self.__values.append(value)\n",
        "\n",
        "        for value in X[self.variables]:\n",
        "          if ',' in value:\n",
        "            for item in value.split(','):\n",
        "              if item.strip() not in self.all_unique_feature_type:\n",
        "                self.all_unique_feature_type.append(item.strip())\n",
        "          else:\n",
        "            if value.strip() not in self.all_unique_feature_type:\n",
        "              self.all_unique_feature_type.append(value.strip())  \n",
        "        \n",
        "        for value in self.__keys[:self.tol]:\n",
        "          if isinstance(value,tuple):\n",
        "            for item in value:\n",
        "              if item.strip() not in self.top_unique_feature_type_:\n",
        "                  self.top_unique_feature_type_.append(item.strip())\n",
        "          elif ',' in value:\n",
        "              for item in value.split(','):\n",
        "                if item.strip() not in self.top_unique_feature_type_:\n",
        "                  self.top_unique_feature_type_.append(item.strip())\n",
        "          else:\n",
        "            if value.strip() not in self.top_unique_feature_type_:\n",
        "              self.top_unique_feature_type_.append(value.strip())\n",
        "\n",
        "        self.top_unique_feature_type_ = self.top_unique_feature_type_ + ['Rare']\n",
        "        self.unique_rare_feature_type_ = [value for value in self.all_unique_feature_type if value not in self.top_unique_feature_type_]\n",
        "\n",
        "        return self\n",
        "\n",
        "  def transform(self, X: pd.DataFrame):\n",
        "        X = X.copy()\n",
        "        \n",
        "        # adding new columns of unique labels in datasets\n",
        "        for value in self.top_unique_feature_type_:\n",
        "          X[f'{self.variables}_{value}'] = np.zeros(X.shape[0])\n",
        "\n",
        "        # Adding 1 and 0's to those newly added columns\n",
        "        for value in self.top_unique_feature_type_:\n",
        "          for index in range(0,X.shape[0]):\n",
        "            if  ',' in  X[self.variables][index]:\n",
        "               for item in X[self.variables][index].split(','):\n",
        "                 if item.strip() not in self.unique_rare_feature_type_:\n",
        "                    X[f'{self.variables}_{value}'][index] = 1\n",
        "                 if item.strip() in self.unique_rare_feature_type_:\n",
        "                   X[f'{self.variables}_Rare'][index] = 1\n",
        "            else:\n",
        "              if value.strip() == X[self.variables][index].strip():\n",
        "                    X[f'{self.variables}_{value}'][index] = 1\n",
        "              if X[self.variables][index].strip() in self.unique_rare_feature_type_:\n",
        "                   X[f'{self.variables}_Rare'][index] = 1      \n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "IwIE9MNidizS"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class handleRankingLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables:str=None,tol:int=10,target:str=None):\n",
        "        self.variables = variables\n",
        "        self.listed_in_ranks = list()\n",
        "        self.tol = tol\n",
        "        self.target = target\n",
        "        self.listed_in_dict = dict()\n",
        "  \n",
        "  # This method checks relation with target columns based on that montonic relation assign ordinal values to top 10 features and map those feature on train and test datasets \n",
        "  def fit(self,X:pd.DataFrame,y:pd.Series = None):\n",
        "    X[self.target] = y\n",
        "    X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "       \n",
        "    if X[self.target].dtypes != float:\n",
        "      X[self.target] = X[self.target].str.replace(',','').astype(float)\n",
        "\n",
        "    if len(df[self.variables].unique()) > 15:\n",
        "      # Get unique top 10 appering categories\n",
        "      self.listed_in_ranks = list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False)[:self.tol].to_dict().keys())\n",
        "    else:\n",
        "      # Get unique top 10 appering categories\n",
        "      self.listed_in_ranks = list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False)[:self.tol].to_dict().keys())\n",
        "\n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "    # replacing non top categories  \n",
        "    X[self.variables] = X[self.variables].apply(lambda value:value if value in self.listed_in_ranks else 'Rare')   \n",
        "          \n",
        "    self.listed_in_ranks = self.listed_in_ranks + ['Rare']\n",
        "\n",
        "    # Creating dictionary for mapping categories \n",
        "    for index in range(0,len(self.listed_in_ranks)):\n",
        "      self.listed_in_dict[self.listed_in_ranks[index]] = index\n",
        "\n",
        "    # replacing categories\n",
        "    X[self.variables] = X[self.variables].map(self.listed_in_dict)    \n",
        "    return X"
      ],
      "metadata": {
        "id": "xFWdtwFKJ7oB"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ZomatoModelTrain(handleMixLabels):\n",
        "\n",
        "  def __init__(self,df):\n",
        "    self.__df = df\n",
        "    self.__target = 'approx_cost(for two people)'\n",
        "    self.__df[self.__target] = self.__df[self.__target].str.replace(',','').astype(float)\n",
        "    self.__random_state = 100\n",
        "    self.__alpha = 0.001\n",
        "    self.__test_size = 0.33\n",
        "    self.__handleMixLabels = handleMixLabels\n",
        "    self.__variable_to_drop = ['url','address','phone','reviews_list','name','dish_liked','menu_item'] + [self.__target]\n",
        "    self.__AddMissingIndicatorVariables = ['votes','rate','location']\n",
        "    self.__MeanMedianImputerVarables = ['votes','location']\n",
        "    self.__CategoricalImputerModeVarables = ['rate','cuisines','rest_type']\n",
        "    self.__LogTransformerVarables = ['votes']\n",
        "    self.__OrdinalEncoderVariables = ['rate','listed_in(type)','listed_in(city)']\n",
        "    self.__OneHotEncoderVariables = ['online_order','book_table','rest_type','cuisines']\n",
        "\n",
        "  def applyModelTrain(self):\n",
        "    X_train,X_test,y_train,y_test = self.__dataSpliter()\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)  \n",
        "    return X_train,X_test,y_train.fillna(y_train.median()),y_test.fillna(y_test.median())\n",
        "\n",
        "  # Splits the data into train and test set\n",
        "  def __dataSpliter(self):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df.drop(self.__variable_to_drop,axis=1), df[self.__target], test_size=self.__test_size, random_state=42)\n",
        "    X_train,X_test,y_train,y_test = X_train.reset_index().drop('index',axis=1),X_test.reset_index().drop('index',axis=1),y_train.reset_index().drop('index',axis=1),y_test.reset_index().drop('index',axis=1)\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)\n",
        "    return X_train,X_test,y_train,y_test\n",
        "\n",
        "  # This method andle noisy data from rate and votes columns\n",
        "  def __dataCleanar(self,X_train,X_test):\n",
        "    # replacing '-' with nan in rate variable\n",
        "    X_train['rate'] = X_train['rate'].replace('-',np.nan)  \n",
        "    X_test['rate'] = X_test['rate'].replace('-',np.nan)\n",
        "\n",
        "    # replacing '0' with nan in votes variable\n",
        "    X_train['votes'] = X_train['votes'].replace(0,np.nan)\n",
        "    X_test['votes'] = X_test['votes'].replace(0,np.nan)\n",
        "    \n",
        "    # replacing '/5' with ' in rates variable\n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    \n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "\n",
        "    return X_train,X_test\n",
        "\n",
        "  # This method is for rate column where based on certain ranges we made this column to categorical oridinal variable\n",
        "  def handleRating(self,X_train,X_test,feature):\n",
        "    return np.where(X_train[feature]==np.nan,np.nan,np.where(X_train[feature]==0,'New',np.where(X_train[feature]<2.5,'Poor',np.where((X_train[feature]>2.5) | (X_train[feature]<3.5),'Average','Good')))),np.where(X_test[feature]==np.nan,np.nan,np.where(X_test[feature]==0,'New',np.where(X_test[feature]<2.5,'Poor',np.where((X_test[feature]>2.5) | (X_test[feature]<3.5),'Average','Good')))) \n",
        "\n",
        "  def featurePipeline(self):\n",
        "    pipe = Pipeline([\n",
        "      # handleRankingLabels\n",
        "      ('handleRankingLabels listed_in(type)',handleRankingLabels(variables='listed_in(type)',tol=10,target=self.__target)), \n",
        "\n",
        "      # handleRankingLabels\n",
        "      ('handleRankingLabels listed_in(city)',handleRankingLabels(variables='listed_in(city)',tol=10,target=self.__target)), \n",
        "\n",
        "      # handleRankingLabels\n",
        "      ('handleRankingLabels location',handleRankingLabels(variables='location',tol=10,target=self.__target)), \n",
        "\n",
        "      #   Missing indicator\n",
        "      ('Add missing indicator',AddMissingIndicator(\n",
        "          variables=self.__AddMissingIndicatorVariables)),\n",
        "    \n",
        "      #   Median Missing Imputation\n",
        "      ('Median Missing Imputation',MeanMedianImputer(\n",
        "          imputation_method='median', variables=self.__MeanMedianImputerVarables)),\n",
        "\n",
        "      #   Mode Missing Imputation\n",
        "      ('Mode Missing Imputation',CategoricalImputer(\n",
        "          imputation_method='frequent', variables=self.__CategoricalImputerModeVarables)),\n",
        "\n",
        "      #  handleMixLabels Imputation\n",
        "      ('handleMixLabels Imputation rest_type', self.__handleMixLabels(\n",
        "          variables='rest_type', target=self.__target, tol=10)),   \n",
        "\n",
        "      #  handleMixLabels Imputation\n",
        "      ('handleMixLabels Imputation cuisines', self.__handleMixLabels(\n",
        "          variables='cuisines', target=self.__target, tol=15)),         \n",
        "\n",
        "      # # Feature Transformation\n",
        "      # ('LogTransformer',LogTransformer(\n",
        "      #     variables=self.__LogTransformerVarables)),\n",
        "\n",
        "      # #  Ordinal Encoder\n",
        "      # ('OrdinalEncoder',OrdinalEncoder(\n",
        "      #     encoding_method='ordered',variables=self.__OrdinalEncoderVariables,unseen='ignore')),\n",
        "\n",
        "      # #  OneHotEncoder\n",
        "      # ('OneHotEncoder',OneHotEncoder(\n",
        "      #     drop_last=True,variables=self.__OneHotEncoderVariables)),\n",
        "\n",
        "      # #  feature selection\n",
        "      # ('feature selection',SelectFromModel(\n",
        "      #     Lasso(alpha=self.__alpha, random_state=self.__random_state)))\n",
        "    ])\n",
        "\n",
        "    return pipe\n"
      ],
      "metadata": {
        "id": "PFjsyhbgZaCk"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/zomato.csv')"
      ],
      "metadata": {
        "id": "FgC9AoxBNIQ2"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zmt = ZomatoModelTrain(df)"
      ],
      "metadata": {
        "id": "1FNr6WINyFua"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = zmt.applyModelTrain()"
      ],
      "metadata": {
        "id": "8H7utpO1ysl-"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xVu433aTFa5",
        "outputId": "03da49ae-7538-440e-9611-993692ca7f52"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34650 entries, 0 to 34649\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   online_order     34650 non-null  object \n",
            " 1   book_table       34650 non-null  object \n",
            " 2   rate             29422 non-null  float64\n",
            " 3   votes            27944 non-null  float64\n",
            " 4   location         34638 non-null  object \n",
            " 5   rest_type        34514 non-null  object \n",
            " 6   cuisines         34621 non-null  object \n",
            " 7   listed_in(type)  34650 non-null  object \n",
            " 8   listed_in(city)  34650 non-null  object \n",
            "dtypes: float64(2), object(7)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'],X_test['rate'] = zmt.handleRating(X_train,X_test,'rate')"
      ],
      "metadata": {
        "id": "T2e-gEmgJ3Qd"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'].unique(),X_test['rate'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEcfeX2pM0UX",
        "outputId": "2c488061-d242-402b-9391-269096412510"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['Good', 'Average', 'New', 'Poor'], dtype=object),\n",
              " array(['Average', 'New', 'Good', 'Poor'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = zmt.featurePipeline()"
      ],
      "metadata": {
        "id": "QaJUNNKL5ILw"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApeYz66MK5B0",
        "outputId": "ba3ed812-89ad-45fc-9a52-20579d02c56d"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('handleRankingLabels listed_in(type)',\n",
              "                 handleRankingLabels(target='approx_cost(for two people)',\n",
              "                                     variables='listed_in(type)')),\n",
              "                ('handleRankingLabels listed_in(city)',\n",
              "                 handleRankingLabels(target='approx_cost(for two people)',\n",
              "                                     variables='listed_in(city)')),\n",
              "                ('handleRankingLabels location',\n",
              "                 handleRankingLabels(target='approx_cost(for two people)',\n",
              "                                     va...\n",
              "                 MeanMedianImputer(variables=['votes', 'location'])),\n",
              "                ('Mode Missing Imputation',\n",
              "                 CategoricalImputer(imputation_method='frequent',\n",
              "                                    variables=['rate', 'cuisines',\n",
              "                                               'rest_type'])),\n",
              "                ('handleMixLabels Imputation rest_type',\n",
              "                 handleMixLabels(target='approx_cost(for two people)',\n",
              "                                 variables='rest_type')),\n",
              "                ('handleMixLabels Imputation cuisines',\n",
              "                 handleMixLabels(target='approx_cost(for two people)', tol=15,\n",
              "                                 variables='cuisines'))])"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(X_train,y_train) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqE0RQid5CmP",
        "outputId": "efd41f40-ce44-44e6-acaf-024f4b7f314e"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('handleRankingLabels listed_in(type)',\n",
              "                 handleRankingLabels(target='approx_cost(for two people)',\n",
              "                                     variables='listed_in(type)')),\n",
              "                ('handleRankingLabels listed_in(city)',\n",
              "                 handleRankingLabels(target='approx_cost(for two people)',\n",
              "                                     variables='listed_in(city)')),\n",
              "                ('handleRankingLabels location',\n",
              "                 handleRankingLabels(target='approx_cost(for two people)',\n",
              "                                     va...\n",
              "                 MeanMedianImputer(variables=['votes', 'location'])),\n",
              "                ('Mode Missing Imputation',\n",
              "                 CategoricalImputer(imputation_method='frequent',\n",
              "                                    variables=['rate', 'cuisines',\n",
              "                                               'rest_type'])),\n",
              "                ('handleMixLabels Imputation rest_type',\n",
              "                 handleMixLabels(target='approx_cost(for two people)',\n",
              "                                 variables='rest_type')),\n",
              "                ('handleMixLabels Imputation cuisines',\n",
              "                 handleMixLabels(target='approx_cost(for two people)', tol=15,\n",
              "                                 variables='cuisines'))])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pipe.transform(X_train)"
      ],
      "metadata": {
        "id": "YWsRDL3s7S_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading"
      ],
      "metadata": {
        "id": "zmz3trVN4UTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(threading.current_thread().is_alive())"
      ],
      "metadata": {
        "id": "LWbxkMpe4X6Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}