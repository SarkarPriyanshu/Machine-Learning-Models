{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTZsXCdsNxh49hm3s+ktJS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarkarPriyanshu/Machine-Learning-Models/blob/main/Zomato_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install feature_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VY_lBjJjWyH",
        "outputId": "614654f9-0393-4c18-92a7-ad22da7e0759"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "56-lh5eoY19C"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import re\n",
        "from typing import List, Optional, Union, Dict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        " \n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.pipeline import Pipeline\n",
        "from feature_engine.imputation import MeanMedianImputer,AddMissingIndicator,CategoricalImputer\n",
        "from feature_engine.transformation import LogTransformer\n",
        "from feature_engine.encoding import OrdinalEncoder,OneHotEncoder\n",
        "\n",
        "\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# to build the models\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Vp-ef-Y8fM",
        "outputId": "c2c71651-2338-457c-9be2-72fceb22e33e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class handleMixLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables: Union[None, str, List[str]] = None,target:str=None,tol:Union[None, int, List[int]]=10):\n",
        "    self.variables = variables\n",
        "    self.__keys:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.__values:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.tol = tol\n",
        "    self.target = target\n",
        "    self.all_unique_feature_type:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.top_unique_feature_type_:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "    self.unique_rare_feature_type_:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "  \n",
        "  # we check the top 10 cardinal value which have monotonic relation with target column store that in keys\n",
        "  # go through the column if it have mixed or comma seperated values the carefully store all unique cardinal values store in all_unique_feature_type\n",
        "  # based on tolerance it take top cardinal values default value is 10 and store those top values in top_unique_feature_type_\n",
        "  def fit(self, X: pd.DataFrame,y:pd.Series):\n",
        "        X = X.dropna().copy()\n",
        "        X[self.target] = y\n",
        "        X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "       \n",
        "        if X[self.target].dtypes != float:\n",
        "          X[self.target] = X[self.target].str.replace(',','').astype(float)\n",
        "\n",
        "        if isinstance(self.variables,list):\n",
        "          self.__keys = list()\n",
        "          for index in len(self.variables):\n",
        "            self.__keys.append({self.variables[index]:list()})\n",
        "            for key,value in X.groupby(self.variables)[self.target].mean().sort_values(ascending=False).items():\n",
        "                    self.__keys[index][self.variables[index]].append(key)\n",
        "                    self.__values[index][self.variables[index]].append(value)\n",
        "\n",
        "            for value in X[self.variables]:\n",
        "              if ',' in value:\n",
        "                for item in value.split(','):\n",
        "                  if item.strip() not in self.all_unique_feature_type:\n",
        "                    self.all_unique_feature_type.append(item.strip())\n",
        "              else:\n",
        "                if value.strip() not in self.all_unique_feature_type:\n",
        "                  self.all_unique_feature_type.append(value.strip())  \n",
        "            \n",
        "            for value in self.__keys[:self.tol]:\n",
        "              if isinstance(value,tuple):\n",
        "                for item in value:\n",
        "                  if item.strip() not in self.top_unique_feature_type_:\n",
        "                      self.top_unique_feature_type_.append(item.strip())\n",
        "              elif ',' in value:\n",
        "                  for item in value.split(','):\n",
        "                    if item.strip() not in self.top_unique_feature_type_:\n",
        "                      self.top_unique_feature_type_.append(item.strip())\n",
        "              else:\n",
        "                if value.strip() not in self.top_unique_feature_type_:\n",
        "                  self.top_unique_feature_type_.append(value.strip())\n",
        "\n",
        "            self.top_unique_feature_type_ = self.top_unique_feature_type_ + ['Rare']\n",
        "            self.unique_rare_feature_type_ = [value for value in self.all_unique_feature_type if value not in self.top_unique_feature_type_]\n",
        "\n",
        "            return self\n",
        "        else:\n",
        "          pass   \n",
        "\n",
        "  def transform(self, X: pd.DataFrame):\n",
        "        X = X.copy()\n",
        "        \n",
        "        # adding new columns of unique labels in datasets\n",
        "        for value in self.top_unique_feature_type_:\n",
        "          X[f'{self.variables}_{value}'] = np.zeros(X.shape[0])\n",
        "\n",
        "        # Adding 1 and 0's to those newly added columns\n",
        "        for value in self.top_unique_feature_type_:\n",
        "          for index in range(0,X.shape[0]):\n",
        "            if  ',' in  X[self.variables][index]:\n",
        "               for item in X[self.variables][index].split(','):\n",
        "                 if item.strip() not in self.unique_rare_feature_type_:\n",
        "                    X[f'{self.variables}_{value}'][index] = 1\n",
        "                 if item.strip() in self.unique_rare_feature_type_:\n",
        "                   X[f'{self.variables}_Rare'][index] = 1\n",
        "            else:\n",
        "              if value.strip() == X[self.variables][index].strip():\n",
        "                    X[f'{self.variables}_{value}'][index] = 1\n",
        "              if X[self.variables][index].strip() in self.unique_rare_feature_type_:\n",
        "                   X[f'{self.variables}_Rare'][index] = 1      \n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "IwIE9MNidizS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class handleRankingLabels(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self,variables: Union[None, str, List[str]] = None,target:str=None,tol:Union[None, int, List[int]]=10):\n",
        "        self.variables = variables\n",
        "        self.listed_in_ranks:Union[None,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "        self.tol = tol\n",
        "        self.target = target\n",
        "        self.listed_in_dict:Union[None,Dict,List[Union[str, Dict[Union[str, int], List[Union[str, int]]]]]] = None\n",
        "\n",
        "        if (isinstance(self.variables,list) and isinstance(self.tol,list)) and (len(self.variables) != len(self.tol)):\n",
        "          raise Exception(\"Number of variable and number of tolerance should be equal in length, check the varables and tol!!\")\n",
        "\n",
        "  \n",
        "  # This method checks relation with target columns based on that montonic relation assign ordinal values to top 10 features and map those feature on train and test datasets \n",
        "  def fit(self,X:pd.DataFrame,y:pd.Series = None):\n",
        "    X[self.target] = y\n",
        "    X[self.target] = X[self.target].fillna(X[self.target].median())\n",
        "       \n",
        "    if X[self.target].dtypes != float:\n",
        "      X[self.target] = X[self.target].str.replace(',','').astype(float)\n",
        "\n",
        "    if isinstance(self.variables,list):\n",
        "      self.listed_in_ranks = list()\n",
        "      for index in range(0,len(self.variables)):\n",
        "        if len(df[self.variables[index]].unique()) > 10:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks.append({f'{self.variables[index]}':list(X.groupby(self.variables[index])[self.target].mean().sort_values(ascending=False)[:self.tol[index]].to_dict().keys())})\n",
        "        else:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks.append({f'{self.variables[index]}':list(X.groupby(self.variables[index])[self.target].mean().sort_values(ascending=False).to_dict().keys())})\n",
        "    elif isinstance(self.variables,str):\n",
        "      self.listed_in_ranks = list()\n",
        "      if len(df[self.variables].unique()) > 10:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks = list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False)[:self.tol].to_dict().keys())\n",
        "      else:\n",
        "          # Get unique top 10 appering categories\n",
        "          self.listed_in_ranks = list(X.groupby(self.variables)[self.target].mean().sort_values(ascending=False).to_dict().keys())\n",
        "    else:\n",
        "      raise Exception(\"Number of variable should be of list or str type.\")    \n",
        "\n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "\n",
        "    if isinstance(self.variables,list):\n",
        "      self.listed_in_dict = list()\n",
        "      list_in_dict = dict()\n",
        "      for index in range(0,len(self.variables)):\n",
        "        # replacing non top categories  \n",
        "        X[self.variables[index]] = X[self.variables[index]].apply(lambda value:value if value in self.listed_in_ranks[index][self.variables[index]] else 'Rare')   \n",
        "              \n",
        "        self.listed_in_ranks[index][self.variables[index]] = self.listed_in_ranks[index][self.variables[index]]+ ['Rare']\n",
        "        # # Creating dictionary for mapping categories \n",
        "        for indx in range(0,len(self.listed_in_ranks[index][self.variables[index]])):\n",
        "           list_in_dict[self.listed_in_ranks[index][self.variables[index]][indx]] = indx\n",
        "        self.listed_in_dict.append({self.variables[index]:list_in_dict})\n",
        "\n",
        "        list_in_dict = dict()\n",
        "        # # replacing categories\n",
        "        X[self.variables[index]] = X[self.variables[index]].map(self.listed_in_dict[index][self.variables[index]]) \n",
        "    \n",
        "    if isinstance(self.variables,str):\n",
        "      self.listed_in_dict = dict()\n",
        "      # replacing non top categories  \n",
        "      X[self.variables] = X[self.variables].apply(lambda value:value if value in self.listed_in_ranks else 'Rare')   \n",
        "            \n",
        "      self.listed_in_ranks = self.listed_in_ranks + ['Rare']\n",
        "      # # Creating dictionary for mapping categories \n",
        "      for index in range(0,len(self.listed_in_ranks)):\n",
        "        print(self.listed_in_ranks[index])\n",
        "        self.listed_in_dict[self.listed_in_ranks[index]] = index\n",
        "\n",
        "      # # replacing categories\n",
        "      X[self.variables] = X[self.variables].map(self.listed_in_dict) \n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "xFWdtwFKJ7oB"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ZomatoModelTrain(handleMixLabels,handleRankingLabels):\n",
        "\n",
        "  def __init__(self,df):\n",
        "    self.__df = df\n",
        "    self.__target = 'approx_cost(for two people)'\n",
        "    self.__df[self.__target] = self.__df[self.__target].str.replace(',','').astype(float)\n",
        "    self.__random_state = 100\n",
        "    self.__alpha = 0.001\n",
        "    self.__test_size = 0.33\n",
        "    self.__handleRankingLabels = handleRankingLabels\n",
        "    self.__handleMixLabels = handleMixLabels\n",
        "    self.__variable_to_drop = ['url','address','phone','reviews_list','name','dish_liked','menu_item'] + [self.__target]\n",
        "    self.__AddMissingIndicatorVariables = ['votes','rate']\n",
        "    self.__MeanMedianImputerVarables = ['votes']\n",
        "    self.__CategoricalImputerModeVarables = ['rate','cuisines','rest_type']\n",
        "    self.__LogTransformerVarables = ['votes']\n",
        "    self.__OrdinalEncoderVariables = ['rate','listed_in(type)','listed_in(city)']\n",
        "    self.__OneHotEncoderVariables = ['online_order','book_table','rest_type','cuisines']\n",
        "\n",
        "  def applyModelTrain(self):\n",
        "    X_train,X_test,y_train,y_test = self.__dataSpliter()\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)  \n",
        "    return X_train,X_test,y_train.fillna(y_train.median()),y_test.fillna(y_test.median())\n",
        "\n",
        "  # Splits the data into train and test set\n",
        "  def __dataSpliter(self):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df.drop(self.__variable_to_drop,axis=1), df[self.__target], test_size=self.__test_size, random_state=42)\n",
        "    X_train,X_test,y_train,y_test = X_train.reset_index().drop('index',axis=1),X_test.reset_index().drop('index',axis=1),y_train.reset_index().drop('index',axis=1),y_test.reset_index().drop('index',axis=1)\n",
        "    X_train,X_test = self.__dataCleanar(X_train,X_test)\n",
        "    return X_train,X_test,y_train,y_test\n",
        "\n",
        "  # This method andle noisy data from rate and votes columns\n",
        "  def __dataCleanar(self,X_train,X_test):\n",
        "    # replacing '-' with nan in rate variable\n",
        "    X_train['rate'] = X_train['rate'].replace('-',np.nan)  \n",
        "    X_test['rate'] = X_test['rate'].replace('-',np.nan)\n",
        "\n",
        "    # replacing '0' with nan in votes variable\n",
        "    X_train['votes'] = X_train['votes'].replace(0,np.nan)\n",
        "    X_test['votes'] = X_test['votes'].replace(0,np.nan)\n",
        "    \n",
        "    # replacing '/5' with ' in rates variable\n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value:str(value).replace('/5',''))\n",
        "    \n",
        "    X_train['rate'] = X_train['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "    X_test['rate'] = X_test['rate'].apply(lambda value: 0 if value == 'NEW' else value).astype(float)\n",
        "\n",
        "    return X_train,X_test\n",
        "\n",
        "  # This method is for rate column where based on certain ranges we made this column to categorical oridinal variable\n",
        "  def handleRating(self,X_train,X_test,feature):\n",
        "    return np.where(X_train[feature]==np.nan,np.nan,np.where(X_train[feature]==0,'New',np.where(X_train[feature]<2.5,'Poor',np.where((X_train[feature]>2.5) | (X_train[feature]<3.5),'Average','Good')))),np.where(X_test[feature]==np.nan,np.nan,np.where(X_test[feature]==0,'New',np.where(X_test[feature]<2.5,'Poor',np.where((X_test[feature]>2.5) | (X_test[feature]<3.5),'Average','Good')))) \n",
        "\n",
        "  def featurePipeline(self):\n",
        "    pipe = Pipeline([\n",
        "      #  Missing indicator\n",
        "      ('Add missing indicator',AddMissingIndicator(\n",
        "          variables=self.__AddMissingIndicatorVariables)),\n",
        "    \n",
        "      #   Median Missing Imputation\n",
        "      ('Median Missing Imputation',MeanMedianImputer(\n",
        "          imputation_method='median', variables=self.__MeanMedianImputerVarables)),\n",
        "\n",
        "      #   Mode Missing Imputation\n",
        "      ('Mode Missing Imputation',CategoricalImputer(\n",
        "          imputation_method='frequent', variables=self.__CategoricalImputerModeVarables)),\n",
        "\n",
        "      # handleRankingLabels\n",
        "      ('handleRankingLabels listed_in(type)',self.__handleRankingLabels(\n",
        "          variables=['listed_in(type)','listed_in(city)','location'],tol=[10,15,15],target=self.__target)),     \n",
        "\n",
        "      #  handleMixLabels Imputation\n",
        "      ('handleMixLabels Imputation rest_type', self.__handleMixLabels(\n",
        "          variables='rest_type', target=self.__target, tol=10)),   \n",
        "\n",
        "      #  handleMixLabels Imputation\n",
        "      ('handleMixLabels Imputation cuisines', self.__handleMixLabels(\n",
        "          variables='cuisines', target=self.__target, tol=15)),         \n",
        "\n",
        "      # Feature Transformation\n",
        "      ('LogTransformer',LogTransformer(\n",
        "          variables=self.__LogTransformerVarables)),\n",
        "\n",
        "      #  Ordinal Encoder\n",
        "      ('OrdinalEncoder',OrdinalEncoder(\n",
        "          encoding_method='ordered',variables=self.__OrdinalEncoderVariables,unseen='ignore')),\n",
        "\n",
        "      #  OneHotEncoder\n",
        "      ('OneHotEncoder',OneHotEncoder(\n",
        "          drop_last=True,variables=self.__OneHotEncoderVariables)),\n",
        "\n",
        "      # #  feature selection\n",
        "      # ('feature selection',SelectFromModel(\n",
        "      #     Lasso(alpha=self.__alpha, random_state=self.__random_state)))\n",
        "    ])\n",
        "\n",
        "    return pipe\n"
      ],
      "metadata": {
        "id": "PFjsyhbgZaCk"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/zomato.csv')"
      ],
      "metadata": {
        "id": "FgC9AoxBNIQ2"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zmt = ZomatoModelTrain(df)"
      ],
      "metadata": {
        "id": "1FNr6WINyFua"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = zmt.applyModelTrain()"
      ],
      "metadata": {
        "id": "8H7utpO1ysl-"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xVu433aTFa5",
        "outputId": "29d9b47b-7de3-4d60-f441-e8559a0e0bad"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34650 entries, 0 to 34649\n",
            "Data columns (total 9 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   online_order     34650 non-null  object \n",
            " 1   book_table       34650 non-null  object \n",
            " 2   rate             29422 non-null  float64\n",
            " 3   votes            27944 non-null  float64\n",
            " 4   location         34638 non-null  object \n",
            " 5   rest_type        34514 non-null  object \n",
            " 6   cuisines         34621 non-null  object \n",
            " 7   listed_in(type)  34650 non-null  object \n",
            " 8   listed_in(city)  34650 non-null  object \n",
            "dtypes: float64(2), object(7)\n",
            "memory usage: 2.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'],X_test['rate'] = zmt.handleRating(X_train,X_test,'rate')"
      ],
      "metadata": {
        "id": "T2e-gEmgJ3Qd"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['rate'].unique(),X_test['rate'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEcfeX2pM0UX",
        "outputId": "9b1888f4-3bd4-4157-e906-1b49a412d071"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['Good', 'Average', 'New', 'Poor'], dtype=object),\n",
              " array(['Average', 'New', 'Good', 'Poor'], dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = zmt.featurePipeline()"
      ],
      "metadata": {
        "id": "FTy-y1foEhh4"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipe.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "YUFQlrEAEm2p"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.handleRankingLabels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "WU3t0NYlF2nb",
        "outputId": "ea404a7b-2158-481f-8f7d-ef2f521f1a3f"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-166-52482f882f38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandleRankingLabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'handleRankingLabels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pipe.transform(X_train)"
      ],
      "metadata": {
        "id": "p8dMOIakFORx"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['listed_in(type)'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPCD2zVYFV0S",
        "outputId": "3250bfc2-62cd-499b-84aa-2315cbeb4a3b"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    17278\n",
              "4    11981\n",
              "6     2428\n",
              "3     1171\n",
              "0      732\n",
              "2      596\n",
              "1      464\n",
              "Name: listed_in(type), dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    }
  ]
}